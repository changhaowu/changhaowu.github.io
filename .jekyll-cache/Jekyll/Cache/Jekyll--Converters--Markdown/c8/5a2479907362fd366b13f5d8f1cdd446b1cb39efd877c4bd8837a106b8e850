I"àa<ul class="table-of-content" id="markdown-toc">
  <li><a href="#generative-model-part-1intuition-on-latent-variable-generative-model" id="markdown-toc-generative-model-part-1intuition-on-latent-variable-generative-model">Generative Model Part 1:Intuition on Latent Variable Generative Model</a>    <ul>
      <li><a href="#intuitionevery-ml-problem-can-be-reduced-to-a-fitting-problem" id="markdown-toc-intuitionevery-ml-problem-can-be-reduced-to-a-fitting-problem">Intuitionï¼šEvery ML problem can be reduced to a fitting problem</a></li>
      <li><a href="#why-latent-variable-model" id="markdown-toc-why-latent-variable-model">Why latent variable model?</a></li>
      <li><a href="#what-to-fit" id="markdown-toc-what-to-fit">What to fit?</a></li>
      <li><a href="#how-good-is-the-fit-" id="markdown-toc-how-good-is-the-fit-">How good is the fit ?</a>        <ul>
          <li><a href="#generative-adversarial-network" id="markdown-toc-generative-adversarial-network">Generative Adversarial Network</a>            <ul>
              <li><a href="#vanilla-gan" id="markdown-toc-vanilla-gan">Vanilla-GAN</a></li>
              <li><a href="#wasserstein-gan" id="markdown-toc-wasserstein-gan">Wasserstein-GAN</a></li>
            </ul>
          </li>
          <li><a href="#variational-autoencoder" id="markdown-toc-variational-autoencoder">Variational autoencoder</a>            <ul>
              <li><a href="#vanilla-vae" id="markdown-toc-vanilla-vae">Vanilla-VAE</a></li>
              <li><a href="#wasserstein-vae" id="markdown-toc-wasserstein-vae">Wasserstein VAE</a></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="generative-model-part-1intuition-on-latent-variable-generative-model">Generative Model Part 1:Intuition on Latent Variable Generative Model</h1>

<p>ä¸ºäº†ä»¥ä¸€ç§åœ¨ç›´è§‰ä¸Šæ›´åˆç†çš„å½¢å¼å»å®šä¹‰ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨ <a href="https://changhaowu.github.io//2020/08/06/Generative-Model-Part-0-Theoretical-Basis-of-Generative-Model/">Generative Model Part 0ï¼šTheoretical Basis of Generative Model</a> å¤–å†è¡¥å……ä¸€ç¯‡ Generative Model Part 1:Intuition on Generative Model ä½¿å¾—ç”Ÿæˆæ¨¡å‹çš„å®šä¹‰æ›´åŠ çš„å¤åˆç›´è§‰ä¸Šçš„ç»“æœï¼Œè€Œä¸æ˜¯ç›´æ¥çš„æ‰”å‡ºä¸€å †ç»“æœ</p>

<p>å› ä¸ºä¸Šè¿°çš„åŸå› ï¼Œè¿™ä¸€ç¯‡çš„å™äº‹è¯­è¨€å¯èƒ½ä¼šæœ‰ä¸€äº›æ€ªï¼Œå°±åƒè¾©è®ºå¼çš„è¯­è¨€ï¼Œè¿™æ ·çš„å™äº‹æ–¹æ³•æ˜¯ç¬¦åˆçœŸç†æ˜¯è¶Šè¾©è¶Šæ˜çš„æƒ³æ³•ï¼Œæˆ–è€…è¯´ï¼Œè¿™ä¸€ç¯‡çš„å™äº‹æ‹Ÿåˆäº†ç¬”è€…åœ¨å†™è¿™ä¸€ç¯‡æ—¶ï¼Œå¤´è„‘ä¸­ä¸¤ä¸ªå°äººåœ¨è¾©è®º X)</p>

<h2 id="intuitionevery-ml-problem-can-be-reduced-to-a-fitting-problem">Intuitionï¼šEvery ML problem can be reduced to a fitting problem</h2>

<p>åœ¨å¸¸è§„çš„æœºå™¨æ¨¡å‹é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬å¸¸åŠªåŠ›æŠŠé—®é¢˜å½’ç»“åˆ°ä¸€ç§æ‹Ÿåˆé—®é¢˜ä¸Šï¼Œè¿™ç§æ‹Ÿåˆæœ‰å¾ˆå¤šç§å½¢å¼ï¼Œæ¯”å¦‚åˆ¤åˆ«æ¨¡å‹å¯ä»¥ç†è§£æˆï¼Œç”¨ä¸€ä¸ªå¤šå±‚ç¥ç»ç½‘ç»œå»å­¦ä¹ ä¸€ä¸ªæ‹Ÿåˆæ¨¡å‹ï¼Œåœ¨ç‰¹å¾æå–å™¨ï¼ˆfeature extractorï¼‰å½¢æˆçš„åƒç©ºé—´ä¸­ï¼Œè¿½æ±‚å¯¹äºåˆ†ç¦»è¶…å¹³é¢çš„æ‹Ÿåˆï¼Œè€Œç”Ÿæˆæ¨¡å‹ \(p_{\theta}\) åœ¨æœ€å¤§ä¼¼ç„¶å‡½æ•°ä¸‹çš„å®šä¹‰ï¼š</p>

\[\theta^* = \arg\max \sum_i^n p_{\theta}(x_i)\]

<p>çœ‹å§ï¼Œé‚£ä¹ˆè¿™ä¸ªæ¨¡å‹æ˜¯åœ¨æ‹Ÿåˆä»€ä¹ˆå‘¢ï¼Ÿç›´è§‰ä¸Šå¾ˆéš¾å›ç­”ï¼Œé‚£ä¹ˆè¿™æ ·å®šä¹‰ä¸‹çš„ç”Ÿæˆæ¨¡å‹åœ¨ç›´è§‰ä¸Šå’Œä¸€èˆ¬çš„æœºå™¨å­¦ä¹ æ¨¡å‹æ˜¯äº§ç”Ÿäº†åˆ†æ­§çš„ï¼Œé‚£ä¹ˆä¸‹é¢å°è¯•ç”¨ â€œæ‹ŸåˆXXâ€ è¿™æ ·çš„æƒ³æ³•æ¥å™äº‹ç”Ÿæˆæ¨¡å‹ï¼ŒåŒæ—¶è¯æ˜ â€œæ‹ŸåˆXXâ€ çš„æƒ³æ³•å…¶å®å’Œæœ€å¤§ä¼¼ç„¶åŸåˆ™ä¸‹çš„æ¨¡å‹æ˜¯ç­‰ä»·çš„</p>

<p>é‚£ä¹ˆå€Ÿé‰´ä¸€äº›åˆ¤åˆ«æ¨¡å‹çš„æ„é€ ï¼Œä¸€ä¸ªç‰¹å¾æå–å™¨ \(f_{\theta}\) ï¼Œä¸€ä¸ªåˆ†ç±»å™¨ \(h_{\phi}\) ï¼Œ\(f_{\theta}\) æ‰§è¡Œä¸€ä¸ªé™ç»´çš„è¿‡ç¨‹ï¼ŒæŠŠé«˜ç»´æ•°æ®æµå½¢é™ç»´åˆ°ä½ç»´ç‰¹å¾ç©ºé—´ \(\Im(f_{\theta})\) ä¸­ï¼Œè¿›ä¸€æ­¥çš„ï¼Œåˆ†ç±»å™¨ \(h_{\phi}\) åœ¨ç‰¹å¾ç©ºé—´ \(\Im(f_{\theta})\) ä¸­å¯»æ‰¾ä¸€ä¸ªåˆ†ç¦»è¶…å¹³é¢ï¼Œé€šè¿‡è¶…å¹³é¢åˆ¤åˆ«è¾“å…¥çš„ç±»åˆ«</p>

<p style="text-align: center;"><img src="/images/2021-05-01-Generative-Model-Part-1-Intuition-on-Generative-Model/illustration_of_discriminative_model.png" alt="illustration_of_discriminative_model" style="zoom:25%;" /></p>

<p>é‚£ä¹ˆç”Ÿæˆæ¨¡å‹ï¼Œæˆ–è€…è¯´åŸºäºéšç©ºé—´çš„ç”Ÿæˆæ¨¡å‹ï¼Œå…¶æƒ³æ³•æ˜¯ç›¸åçš„ï¼ŒæŠŠä½ä½éšç©ºé—´ä¸­çš„æ— æ„ä¹‰å™ªå£°æ˜ å°„åˆ°é«˜ç»´æ•°æ®æµå½¢ä¸Šï¼Œå¥½åƒæ˜¯åªè¦ä¸€ä¸ªç”Ÿæˆæ˜ å°„ \(g_{\theta}\) æŠŠä»éšç©ºé—´ä¸­é‡‡æ ·çš„ \(z\) æ˜ å°„åˆ° \(g(\theta) \in X\) ä¸­å°±å¥½äº†ï¼ˆåªè¦ä¸€ä¸ªå‚æ•°ï¼Œäº‹æƒ…å°‘äº†ä¸€åŠï¼‰ï¼Œä½†æ˜¯å¹¶ä¸æ˜¯ï¼Œè¿™æ˜¯è®­ç»ƒå®Œçš„ç”Ÿæˆæ¨¡å‹ï¼Œä½†æ˜¯ä¸ºäº†è®­ç»ƒç”Ÿæˆæ¨¡å‹ï¼Œè¿˜éœ€è¦å¦å¤–ä¸€ä¸ªå‚æ•° \(\phi\) ï¼Œâ€œThereâ€˜s no silver bulletâ€</p>

<p style="text-align: center;"><img src="/images/2021-05-01-Generative-Model-Part-1-Intuition-on-Generative-Model/no-silver-bullet.png" alt="no-silver-bullet" style="zoom:50%;" /></p>

<h2 id="why-latent-variable-model">Why latent variable model?</h2>

<p>é‚£ä¹ˆæŒ‰ç…§ â€œæ‹ŸåˆXXâ€ çš„æ€è·¯å»æ„å»ºæ¨¡å‹ï¼Œè¿™ä»¶äº‹æƒ…æ˜¯åˆ†æˆä¸¤æ­¥çš„ï¼Œæ‹Ÿåˆçš„ç›®æ ‡ä»¥åŠæ‹Ÿåˆç¨‹åº¦çš„åº¦é‡</p>

<p>ä½†æ˜¯é¦–å…ˆï¼Œå†å¾€å‰é€€ä¸€æ­¥ï¼Œè¦ç¡®å®šæ˜¯æŒ‡å¯¼å»ºç«‹æ¨¡å‹çš„æ€æƒ³ï¼Œå°±æ˜¯ä¸ºä»€ä¹ˆå¯ä»¥é€šè¿‡éšç©ºé—´æ„é€ ç”Ÿæˆæ¨¡å‹è¿™ä»¶äº‹æƒ…ï¼Œè¿™æ˜¯ä¸æ˜¾ç„¶çš„ï¼Œæœ‰äº›å›°æƒ‘çš„ï¼Œæ¯”å¦‚æ‹¿ä¸€ä¸ª \(28 \times 28\) çš„ \(\textit{minst}\) å­—ä½“æ¥è¯´ï¼Œä¸€ç§è‡ªç„¶çš„æƒ³æ³•å½“ç„¶æ˜¯ï¼š</p>

\[p(x)=\prod_{i=1}^{D} p\left(x_{i} \mid x_{&lt;i}\right)\]

<p>è€Œä¸æ˜¯é€šè¿‡éšç©ºé—´æ„é€ çš„ï¼š</p>

\[p(x)=\int p_{\theta}(x \mid z) p_{z}(z) d z = \sum_1^n  p_{\theta}(x \mid z_i) p_{z}(z_i)\]

<p>ä¸‹é¢é‚£ä¸ªéšç©ºé—´çš„æƒ³æ³•ç”šè‡³éƒ½æ— æ³•é¡ºåˆ©çš„è®¡ç®—ï¼ˆéšç©ºé—´é‡‡æ ·åˆ°åº•å¤šå°‘æ˜¯åˆé€‚çš„å‘¢ï¼Ÿï¼‰</p>

<p>ä¸Šé¢é‚£ä¸ªåˆ†è§£ä¹Ÿæ˜¯èƒ½åšçš„ï¼Œä½†æ˜¯çœ‹è¿™ä¸ªåˆ†è§£å°±çŸ¥é“ï¼Œå®ƒä¸¥é‡çš„è¿åäº†è®¾è®¡æ·±åº¦å­¦ä¹ ç®—æ³•æ‰€éœ€è¦çš„å¹¶è¡Œè®¡ç®—çš„è¿‡ç¨‹ï¼Œè¿™ä¼šå¯¼è‡´å…¶è®¡ç®—ç¼“æ…¢</p>

<p>æ›´é‡è¦çš„æ˜¯ï¼Œæ ¹æ®éšç©ºé—´å»ºæ¨¡è¿™ä»¶äº‹æƒ…ç¬¦åˆä¸€äº›å®éªŒä¸­è§‚å¯Ÿåˆ°çš„äº‹å®åŒæ—¶åˆé™ä½äº†æ¨¡å‹çš„å¤æ‚åº¦ï¼š</p>

<ol>
  <li>
    <p>æ¯”å¦‚ \(28 \times 28\) çš„ \(\textit{minst}\) å­—ä½“æ¥è¯´ï¼Œç”±äºå®éªŒä¸Šå¯çŸ¥ï¼Œé€šè¿‡åˆ¤åˆ«æ¨¡å‹å¯ä»¥å¯¹æ•°æ®è¿›è¡Œå¾ˆå¥½çš„åˆ†ç±»ï¼Œä»¥tensorflow coreæä¾›çš„ç½‘ç»œä¸ºä¾‹ï¼Œä»ç‰¹å¾æå–å™¨è¾“å‡ºçš„ç»´åº¦æ˜¯128ç»´ï¼Œæ¯”èµ·åŸæ¥çš„784ç»´å°äº†å¾ˆå¤šï¼Œæ›´ä¸é‘è®ºæ›´æ·±çš„ç½‘ç»œï¼Œæå–å™¨è¾“å‡ºçš„ç»´åº¦æ¯”128ç»´è¿˜è¦å°å¾ˆå¤šï¼Œè¿™ç§ç°è±¡è¢«æ€»ç»“æˆæµå½¢åˆ†å¸ƒå¾‹ï¼šæ¯”èµ·å¼¥æ•£åœ¨æ•´ä¸ªç©ºé—´ä¸­ï¼ŒåŒæºåŒç±»çš„æ•°æ®æ›´å€¾å‘äºåˆ†å¸ƒåœ¨ä¸€ä¸ªé«˜ç»´æµå½¢é™„è¿‘ï¼Œè¿™æ”¯æŒæˆ‘ä»¬å»è®­ç»ƒä¸€ä¸ªå¤æ‚åº¦æ›´ä½çš„ç½‘ç»œï¼Œæ›´å°‘çš„è®­ç»ƒé‡ï¼Œè¾¾åˆ°çš„æ‹Ÿåˆæ•ˆæœæ˜¯å·®ä¸å¤šçš„</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()</span>
       
    <span class="c1">### just one layer convolution, the complexity of model ###  &lt;- Here!!
</span>       
    <span class="bp">self</span><span class="p">.</span><span class="n">d1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">d2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
   
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">d1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">d2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
   
<span class="c1"># Create an instance of the model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>é‚£ä¹ˆæ¢ä¸€ç§æ€è·¯ï¼Œä»ä»¿ç”Ÿçš„è§’åº¦æ¥è¯´ï¼Œæˆ‘ä»¬å¹³æ—¶å†™ä¸€ä¸ªæ•°å­—ï¼Œè„‘å­é‡ŒçœŸçš„æƒ³äº†784ä»¶ç‹¬ç«‹çš„äº‹æƒ…å˜›ï¼Ÿç›¸åï¼Œæˆ‘ä»¬å¯èƒ½è€ƒè™‘ç¬”é¡ºå¦‚ä½•ï¼Ÿå¼¯æŠ˜å¦‚ä½•ï¼Ÿè¿™æ ·çš„æ›´æŠ½è±¡çš„äº‹æƒ…ï¼Œè€Œä¸æ˜¯æ€è€ƒ784ä¸ªpixelæ˜¯ä¸æ˜¯è¦æ¶‚é»‘ã€‚è¿›ä¸€æ­¥çš„ï¼Œè‹¥æ˜¯æ”¾å¤§è¿™ä¸ªæ•°å­— \(2\times2\) å€ï¼Œéš¾é“æˆ‘ä»¬æƒ³çš„äº‹æƒ…ä¼šå¤š4å€å˜›ï¼Ÿ</p>
  </li>
</ol>

<p>å› æ­¤ï¼Œé€šè¿‡éšç©ºé—´æ¥å»ºæ¨¡ç”Ÿæˆæ¨¡å‹ï¼Œæ—¢æœ‰ç¡¬ä»¶è®¡ç®—ä¸Šçš„å¥½å¤„ï¼ŒåŒæ—¶åˆç¬¦åˆè§‚å¯Ÿåˆ°çš„å®éªŒç°è±¡ï¼Œé‚£ä¹ˆå¥½è¯è¯´å®Œäº†ï¼Œè¯¥è¯´ä¸å¥½çš„äº†ï¼Œæ­£å¦‚ä¹‹å‰æ‰€è¯´çš„ï¼š</p>

\[p(x)=\int p_{\theta}(x \mid z) p_{z}(z) d z\]

<p>è¿™ä¸ªå¼å­åœ¨è®¡ç®—ä¸Šæ˜¯intractabilityï¼Œé‚£ä¹ˆå°±éœ€è¦é€šè¿‡ç»•è·¯çš„åŠæ³•æ¥å»ºæ¨¡éµå¾ªéšç©ºé—´æƒ³æ³•çš„ç”Ÿæˆæ¨¡å‹</p>

<h2 id="what-to-fit">What to fit?</h2>

<p>æ ¹æ® â€œè¦å­¦ä¹ ä¸€ä¸ªå¥½çš„ç”Ÿæˆæ˜ å°„â€ è¿™ä»¶äº‹æƒ…æ¥å»ºç«‹ä¸€ä¸ªæ‹Ÿåˆçš„ç›®æ ‡ï¼Œä»¿ç…§ä¹‹å‰çš„åˆ¤åˆ«æ¨¡å‹çš„å»ºç«‹ï¼Œåˆ†æˆä¸¤æ­¥æ¥åšï¼š</p>

<p>é‚£ä¹ˆå¦‚ä½•ç¡®å®šè¿™ä¸¤æ­¥å‘¢ï¼ŸGANï¼ˆGenerative Adversarial Networkï¼‰å’Œ VAE ï¼ˆVaraitional Autoencoderï¼‰åˆ†åˆ«æä¾›äº†ä¸¤ç§æ€è·¯ï¼š</p>

<ol>
  <li>GANï¼šæœ€åè¦çš„æ˜¯ä¸€ä¸ªå¥½çš„ç”Ÿæˆæ˜ å°„ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªçœŸå®çš„æ•°æ®åˆ†å¸ƒï¼Œé‚£ä¹ˆç›´æ¥è¿½æ±‚å¥½çš„ç”Ÿæˆæ˜ å°„ã€‚ç¬¬ä¸€æ­¥é€šè¿‡ç”Ÿæˆæ˜ å°„ \(G\) æŠŠéšç©ºé—´é‡‡æ ·æ˜ å°„åˆ°é«˜ç»´ç©ºé—´ä¸­ï¼Œç¬¬äºŒæ­¥é€šè¿‡çœŸå®æ•°æ®è®­ç»ƒä¸€ä¸ªåº¦é‡ \(D\) ï¼Œæ¥åº¦é‡â€æœ‰å¤šåƒä»æ•°æ®é›†ä¸­é‡‡æ ·çš„æ•°æ®â€ï¼Œè¿™æ ·çš„ä¸¤æ­¥æ¥è®¾è®¡ç®—æ³•</li>
  <li>VAEï¼šé‚£ä¹ˆæ—¢ç„¶æœ‰éšç©ºé—´çš„æƒ³æ³•æ”¯æŒï¼Œä¸å¦¨ä»¿ç…§autoencoderçš„æƒ³æ³•ï¼Œå»ºç«‹éšç©ºé—´æ¦‚ç‡åˆ†å¸ƒå’Œæ•°æ®ç©ºé—´æ¦‚ç‡åˆ†å¸ƒçš„å…³ç³»ï¼Œæ¯”èµ·GANæ”¾å¼ƒäº†å¯¹åˆ†å¸ƒçš„æŠŠæ¡ï¼ŒVAEä¿ç•™äº†è¿™ä¸€ç‚¹ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé€šè¿‡ç¼–ç å™¨ \(p_{\theta}\) å’Œè§£ç å™¨ \(q_{\phi}\) æ¥æ¨¡ä»¿å¤å»ºçš„è¿‡ç¨‹ï¼Œæœ€åä»è®­ç»ƒå¥½çš„ç”Ÿæˆåˆ†å¸ƒä¸­é‡‡æ ·ï¼Œè¿™æ ·çš„ä¸¤æ­¥æ¥è®¾è®¡ç®—æ³•</li>
</ol>

<p>ç”»å›¾æ¥è¯´çš„è¯å°±æ˜¯å¦‚ä¸‹æ‰€ç¤ºï¼š</p>

<p style="text-align: center;"><img src="/images/2021-05-01-Generative-Model-Part-1-Intuition-on-Generative-Model/two_step_GAN_VAE.png" alt="two_step_GAN_VAE" style="zoom:30%;" /></p>

<p>ä½†æ˜¯è¿™æ ·çœ‹çš„è¯ï¼Œä¸¤è€…åœ¨ç»“æ„ä¸Šå°±ä¼¼ä¹æ¯«æ— å…³ç³»ï¼Œä¸ºäº†æ›´å¥½çš„ç»Ÿä¸€èµ·æ¥ï¼Œéœ€è¦æ›´é«˜ä¸€äº›çš„è§‚ç‚¹ï¼Œåœ¨æ•°æ®æµå½¢æ‹Ÿåˆè¿™ä¸ªå…±åŒç›®æ ‡ä¸‹ï¼Œå°±èƒ½è¢«ç»Ÿä¸€èµ·æ¥ï¼š</p>

<p style="text-align: center;"><img src="/images/2021-05-01-Generative-Model-Part-1-Intuition-on-Generative-Model/data_manifold_fit.png" alt="data_manifold_fit" style="zoom:30%;" /></p>

<p>ä¸¤è€…éƒ½æ˜¯ä»éšç©ºé—´å‡ºå‘ï¼Œè§£ç å™¨ \(p_{\theta}\) å’Œç”Ÿæˆæ˜ å°„ \(G\) çš„ä½œç”¨æ˜¯ç±»ä¼¼çš„ï¼Œä½†æ˜¯åŒºåˆ«åœ¨äºä¸ºäº†åº¦é‡ç”Ÿæˆæ˜ å°„ \(G\)ï¼ŒGANçš„ç¬¬äºŒéƒ¨åˆ†éœ€è¦ä¸€ä¸ªåˆ¤åˆ«å™¨ï¼Œè€Œç›¸å¯¹åº”çš„ï¼ŒVAEç›´æ¥ä½¿ç”¨åŸæ¥æ•°æ®ç©ºé—´ä¸­çš„æµ‹åº¦æŠŠè§£ç å™¨åˆ†å¸ƒ \(p_{\theta}\) ç»éªŒåˆ†å¸ƒæ¯”è¾ƒå³å¯ï¼Œä½†æ˜¯å»ºç«‹éšç©ºé—´çš„åˆ†å¸ƒå’Œæ•°æ®ç©ºé—´çš„åˆ†å¸ƒä¹‹é—´çš„åŒå‘å…³ç³»ï¼Œéœ€è¦ç›¸åº”çš„è®­ç»ƒä¸€ä¸ªç¼–ç å™¨åˆ†å¸ƒ \(q_{\phi}\)</p>

<h2 id="how-good-is-the-fit-">How good is the fit ?</h2>

<p>æœ‰äº†æ‹Ÿåˆçš„ç›®æ ‡ï¼ˆæŠŠæ•°æ®åˆ†å¸ƒå’Œç”Ÿæˆåˆ†å¸ƒè¿›è¡Œæ‹Ÿåˆï¼‰ï¼Œå°±éœ€è¦å»å»ºç«‹è¡¡é‡æ‹Ÿåˆç¨‹åº¦çš„æŒ‡æ ‡ï¼Œæ¥ä¸‹æ¥æŠŠä¸¤ç±»æ¨¡å‹åˆ†å¼€æ¥è®²ï¼š</p>

<h3 id="generative-adversarial-network">Generative Adversarial Network</h3>

<p>ç”±äºGANè‡ªå¸¦ä¸€ä¸ªåˆ¤åˆ«å™¨å……å½“åº¦é‡ï¼Œé‚£ä¹ˆç°åœ¨è¦åšçš„å°±æ˜¯é€šè¿‡åˆ¤åˆ«å™¨ \(D\) æ¥è¡¡é‡æ•°æ®åˆ†å¸ƒ \(p_{data}\) å’Œç”Ÿæˆåˆ†å¸ƒ \(p_{G}\) ä¹‹é—´çš„è·ç¦»</p>

<h4 id="vanilla-gan">Vanilla-GAN</h4>

<p>åœ¨vanilla-GANä¸­ï¼Œgoodfellowæ˜¯åˆ©ç”¨ä¸€ç§â€œè®¡æ•°â€çš„æ€æƒ³ï¼Œæ„é€ äº†ä¸€ä¸ªæŸå¤±å‡½æ•°ï¼ŒåŒæ—¶è¯æ˜äº†æ„é€ çš„æŸå¤±å‡½æ•°åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­æ˜¯å¯¹äº Jenson-Shannon divergence çš„ä¸€ä¸ªé€¼è¿‘ï¼š</p>

<p>é‚£ä¹ˆé¦–å…ˆä»ç›´è§‰ä¸Šæ„é€ æŸå¤±å‡½æ•°ï¼Œæˆ‘å¸Œæœ›åˆ¤åˆ«å™¨æå‡çš„è¯ï¼Œé‚£ä¹ˆå°±æ˜¯åˆ†è¾¨çš„å‡ºç”Ÿæˆå™¨ä¸­å‡ºæ¥æ•°æ®ï¼ŒåŒæ—¶ä¸è¯¯åˆ¤çœŸå®çš„æ•°æ®ï¼ŒåŒæ—¶ç”Ÿæˆå™¨è¦èƒ½å¤Ÿå°½å¯èƒ½çš„ä½¿ç”Ÿæˆæ•°æ®è¢«è¯¯è®¤ä¸ºçœŸå®æ•°æ®ï¼Œé‚£ä¹ˆå‡å°‘è¯¯åˆ†ç±»çš„æ•°æ®å’Œå¢åŠ åˆ†ç±»å¥½çš„æ•°æ®æ˜¯åˆ¤åˆ«å™¨çš„å·¥ä½œï¼ŒåŒæ—¶ç”Ÿæˆå™¨å°±è¦å°½å¯èƒ½éª—è¿‡åˆ¤åˆ«å™¨</p>

\[\min _{G} \max _{D} V(D, G)=\min _{G} \max _{D}  \mathbb{E}_{\boldsymbol{x} \sim p_{\mathrm{data}}(\boldsymbol{x})}[D(\boldsymbol{x})]+\mathbb{E}_{\mathbf{z} \sim p_{\boldsymbol{z}}(\mathbf{z})}[1-D(G(\mathbf{z}))]\]

<p>é‚£ä¹ˆè¿™æ ·çš„æŸå¤±å‡½æ•°æ˜¯å¯ä»¥åšåˆ°è¦æ±‚çš„ï¼Œä¸ºäº†ä¸å¤±æ¨¡å‹çš„æ³›åŒ–æ€§ï¼Œæ”¹å†™æˆï¼š</p>

\[\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\mathrm{data}}(\boldsymbol{x})}[f(D(\boldsymbol{x}))]+\mathbb{E}_{\mathbf{z} \sim p_{\boldsymbol{z}}(\mathbf{z})}[f(1-D(G(\mathbf{z}))]\]

<p>è¿™æ ·çš„åˆ¤åˆ«å‡½æ•°å½“ç„¶æ˜¯ç¬¦åˆç›´è§‰çš„ï¼Œä½†æ˜¯åœ¨ç¬¦åˆç›´è§‰çš„åŒæ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨ç†è®ºç»™äºˆæ”¯æ’‘ï¼Œæ¢è¨€ä¹‹ï¼Œå¦‚æœè¿™ä¸ªæ¨¡å‹æ˜¯æŸç§åˆ†å¸ƒçš„è·ç¦»çš„é€¼è¿‘ï¼Œè¿™æ ·æ˜¯æ‰æ˜¯ç¬¦åˆç†è®ºçš„æ–¹æ³•ï¼Œè€Œ Vanilla-GAN ä¸­ä¹Ÿè¯æ˜äº†è¿™ä¸€ç‚¹ï¼š</p>

<ol>
  <li>
    <p>é¦–å…ˆå›ºå®šç”Ÿæˆå™¨ \(G\)ï¼Œå»æ±‚å‡ºæœ€ä¼˜çš„åˆ¤åˆ«å™¨ \(D\)ï¼š</p>

\[\begin{aligned}
V(G, D) &amp;=\int_{\boldsymbol{x}} p_{\text {data }}(\boldsymbol{x}) \log (D(\boldsymbol{x})) d x+\int_{\boldsymbol{z}} p_{\boldsymbol{z}}(\boldsymbol{z}) \log (1-D(g(\boldsymbol{z}))) d z \\
&amp;=\int_{\boldsymbol{x}} p_{\text {data }}(\boldsymbol{x}) \log (D(\boldsymbol{x}))+p_{g}(\boldsymbol{x}) \log (1-D(\boldsymbol{x})) d x
\end{aligned}\]

    <p>ç”±äº \(y \rightarrow a \log (y)+b \log (1-y)\) åœ¨ \([0,1]\) ä¸Šåœ¨ \(\frac{a}{a+b}\) å–åˆ°æœ€ä¼˜ï¼Œå› æ­¤æœ€ä¼˜çš„åˆ¤åˆ«å™¨æ˜¯ \(\frac{p_{\text {data }}(x)}{P_{\text {data }}(x)+p_{g}(x)}\)</p>
  </li>
  <li>
    <p>åœ¨æ­¤ä¹‹ä¸Šå›ºå®šåˆ¤åˆ«å™¨ \(D\)ï¼Œè¿™å…¶å®èƒ½å¤Ÿå……å½“ä¸€ä¸ªè·ç¦» \(D(p_{g},p_{data})\)ï¼š</p>

\[\begin{aligned}
D(p_{g},p_{data})&amp;=\max _{D} V(G, D) \\
&amp;=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}}\left[\log \left(1-D_{G}^{*}(G(\boldsymbol{z}))\right)\right] \\
&amp;=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \left(1-D_{G}^{*}(\boldsymbol{x})\right)\right] \\
&amp;=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log \frac{p_{\text {data }}(\boldsymbol{x})}{P_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \frac{p_{g}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right]
\\
&amp; = -\log (4)+K L\left(p_{\text {data }} \| \frac{p_{\text {data }}+p_{g}}{2}\right)+K L\left(p_{g} \| \frac{p_{\text {data }}+p_{g}}{2}\right)
\\
&amp; = -\log (4)+2 \cdot J S D\left(p_{\text {data }} \| p_{g}\right)
\end{aligned}\]
  </li>
</ol>

<p>é‚£ä¹ˆè¯´æ˜vanilla-GANåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœ¬èº«å°±æ˜¯åœ¨æ‹Ÿåˆä¸€ä¸ª \(JS\) æ•£åº¦</p>

<h4 id="wasserstein-gan">Wasserstein-GAN</h4>

<p>é‚£ä¹ˆç°åœ¨å›åˆ°æ•£åº¦æœ¬èº«ï¼Œæ— è®ºæ˜¯ \(KL\) æ•£åº¦æŠ‘æˆ–æ˜¯ \(JS\) æ•£åº¦ï¼Œéƒ½å¯ä»¥ç»Ÿä¸€åœ¨ \(f-divergence\) ä¸‹ï¼Œ \(f-divergence\) å¯ä»¥å……å½“ä¸€ä¸ªåˆ†å¸ƒä¹‹é—´çš„è·ç¦»ï¼š</p>

\[D_{f}(P \| Q) \equiv \int_{\Omega} f\left(\frac{d P}{d Q}\right) d Q\]

<p>å¹¶ä¸”æœ‰ä»¥ä¸‹çº¦æŸï¼š</p>

<ol>
  <li>\(f\)  æ˜¯å‡¸å‡½æ•°ä¸” \(f(1)=0\)</li>
  <li>\(P\) åœ¨ \(Q\) çš„æ„ä¹‰ä¸‹ï¼Œåœ¨ \(\Omega\) ä¸Šè¿ç»­</li>
</ol>

<p>é‚£ä¹ˆå…ˆå›åˆ°ä¹‹å‰vanilla-GANä¸­å®šä¹‰çš„ \(p_{data}\) ï¼Œè¿™ä¸ªæ˜¯çœŸå®æ•°æ®åˆ†å¸ƒï¼Œè¿™åªèƒ½è¯´æ˜ \(p_{data}\) æ˜¯å­˜åœ¨çš„ï¼Œè€Œæ²¡æœ‰æä¾›ç»™æˆ‘ä»¬ä¸€ä¸ªå¦‚ä½• \(p_{data}\) çš„åŠæ³•ï¼Œé‚£ä¹ˆå¦‚ä½•å¯¹äº \(p_{data}\) åšä¸€ä¸ªåˆç†çš„é€¼è¿‘å‘¢ï¼Ÿ</p>

<p>ç»éªŒåˆ†å¸ƒå‡½æ•°å¯èƒ½æ˜¯ä¸€ä¸ªåˆç†çš„é€‰æ‹©ï¼Œæœ‰æ•°æ®é›† \(X=\left\{x_{1}, x_{2}, \ldots, x_{n}\right\}\)ï¼Œé€šè¿‡ \(\delta\) å‡½æ•°å®šä¹‰ç»éªŒåˆ†å¸ƒå‡½æ•°ï¼š</p>

\[\mu_{X}(x)=\frac{1}{n} \sum_{i=1}^{n} \delta x_{i}(x)\]

<p>é‚£ä¹ˆå½“é‡‡æ ·è¶³å¤Ÿå¤šçš„æ—¶å€™ï¼Œç»éªŒåˆ†å¸ƒå‡½æ•°æ˜¯å¯ä»¥é€¼è¿‘æ•°æ®åˆ†å¸ƒ \(p_{data}\) çš„</p>

<p>é‚£ä¹ˆé—®é¢˜å°±å¯ä»¥è½¬åŒ–æˆï¼Œç°åœ¨è¦è®­ç»ƒä¸€ä¸ªç”Ÿæˆæ¨¡å‹ \(g_{\theta}\)ï¼Œå»ä¼˜åŒ– \(Distance(g_{\theta},\mu_{X})\) ï¼Œæ¯”èµ·ä¹‹å‰æ‰€è¯´çš„æ¯”è¾ƒæŠ½è±¡çš„æ‹Ÿåˆæ•°æ®åˆ†å¸ƒï¼Œè¿™æ ·å°±è·Ÿåˆ‡å®äº†</p>

<p>\(f-divergence\) åœ¨ \(\mu_{X}(x)\) ä¸‹å°±äº§ç”Ÿäº†å®šä¹‰ä¸Šçš„é—®é¢˜ï¼Œå› ä¸º \(\mu_{X}\) æ˜¯ä¸€ä¸ªç¦»æ•£çš„åˆ†å¸ƒï¼Œ\(supp(\mu_{X}) = \left\{x_{1}, x_{2}, \ldots, x_{n}\right\}\) ï¼Œåœ¨æ­¤ä¹‹å¤–çš„éƒ¨åˆ†æ— æ³•å»è®¡ç®—  \(Distance(g_{\theta},\mu_{X})\) ï¼Œè¿™æ ·çš„è¯å°±æ— æ³•ç”¨æ¥æœ‰æ•ˆè¿›è¡Œ SGD ï¼Œé‚£ä¹ˆåŸºäºé€¼è¿‘ \(JS-divergence\) çš„ vanilla-GAN ä¼šå‡ºç°éš¾ä»¥è®­ç»ƒçš„é—®é¢˜ä¹Ÿæ˜¯æ­£å¸¸çš„äº†</p>

<p>åœ¨è¿™æ ·çš„èƒŒæ™¯ä¸‹ï¼Œå»æ‰¾ä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆè®¡ç®— \(Distance(g_{\theta},\mu_{X})\) çš„è·ç¦»ä¹Ÿå°±ä¸å¥‡æ€ªäº†ï¼Œ\(Wasserstein\) è·ç¦»å‘¼ä¹‹æ¬²å‡ºï¼Œå…³äº \(Wasserstein\) è·ç¦»çš„åŸºç¡€éƒ¨åˆ† <a href="https://changhaowu.github.io/2021/01/20/Optimal-Transport-Note-Part-1/">æœ€ä¼˜ä¼ è¾“</a></p>

<p>æœ‰äº†åˆé€‚çš„è·ç¦»åï¼Œåœ¨è¿™ä¸ªæ¡†æ¶ä¸‹å®¡è§† \(Wasserstein \; GAN\)ï¼Œé€šè¿‡ \(Wasserstein\) è·ç¦»æ¥ä¼˜åŒ–ç»éªŒåˆ†å¸ƒå’Œç”Ÿæˆåˆ†å¸ƒé—´çš„è·ç¦»ï¼š
\(W_{p}(g_{\theta},\mu_{X}):=\left(\inf _{\gamma \in \Gamma(g_{\theta},\mu_{X})} \int_{X \times X} d(x, y)^{p} \mathrm{~d} \gamma(x, y)\right)^{1 / p}\)</p>

<p>ä½†æ˜¯è¿™æ ·çš„è¯ï¼Œç”±äºè¦ä¼˜åŒ–çš„å‚æ•° \(\theta\) å‡ºç°åœ¨äº† constraint ä¸Šï¼Œä¼šå¯¹æ±‚è§£æ¢¯åº¦é€ æˆå½±å“ï¼Œè€ƒè™‘å¯¹å¶é—®é¢˜ï¼š</p>

<p>è¿›ä¸€æ­¥å– \(p=1\) ï¼Œæœ‰ \(Kantorvich-Rubinstein \; Duality\)ï¼š</p>

\[W_{p}(g_{\theta},\mu_{X}):= \sup _{|\mid f \|_{L} \leq 1}[\underset{x \sim g_{\theta}}{\mathbb{E}}[f(x)]-\underset{y \sim \mu_{X}}{\mathbb{E}}[f(y)]]\]

<p>è¿™æ ·çº¦æŸå˜æˆäº†åœ¨æ»¡è¶³ \(\| f \|_{L} \leq 1\) çš„å‡½æ•°ä¸­å–åº·æ‰˜ç½—ç»´å¥‡åŠ¿èƒ½ \(\tilde{f}\) å³å¯</p>

<p>ä½†æ˜¯çœŸæ­£åº”ç”¨çš„æ—¶å€™ï¼Œæ¯æ¬¡éƒ½å®Œæ•´è®¡ç®—ä¸€æ¬¡ \(Wasserstein\) è·ç¦»ï¼Œè¿™æ ·è®¡ç®—é‡ä¼šçˆ†ç‚¸çš„ï¼Œå› æ­¤è®­ç»ƒä¸€ä¸ªä»¥ \(w\) ä¸ºå‚æ•°çš„ \(f_{w}\) çš„ç¥ç»ç½‘ç»œä½œä¸º \(Wasserstein\) è·ç¦»çš„ä¼°è®¡ï¼Œä¸ºäº†é™åˆ¶ \(f_{w}\) åœ¨ \(\| f \|_{L} \leq 1\) ä¸­ï¼Œé‡‡ç”¨weight clipæŠ€å·§</p>

<p>æ•´ç†ä¸€ä¸‹ \(Wasserstein \; GAN\) çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¯ä»¥æ€»ç»“å‡ºè¿™æ ·çš„loss functionï¼š</p>

\[\min_{\theta}\max _{w \in \mathcal{W}} \mathbb{E}_{x \sim \mathbb{P}_{r}}\left[f_{w}(x)\right]-\mathbb{E}_{z \sim p(z)}\left[f_{w}\left(g_{\theta}(z)\right]\right.\]

<p>é‚£ä¹ˆæœ‰ä¸¤ä»¶äº‹æƒ…å€¼å¾—ä¸€æï¼š</p>

<ol>
  <li>
    <p>çœ‹èµ·æ¥å’Œ vanilla-GAN çš„ loss function æœ‰å¼‚æ›²åŒå·¥ä¹‹å¦™ï¼š</p>

\[\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\mathrm{data}}(\boldsymbol{x})}[f(D(\boldsymbol{x}))]+\mathbb{E}_{\mathbf{z} \sim p_{\boldsymbol{z}}(\mathbf{z})}[f(1-D(G(\mathbf{z}))]\]

    <p>æ²¡é”™ï¼Œè¿™ä¸€ç±»è®¾è®¡ä¼˜åŒ–å‡½æ•°çš„æ€æƒ³ï¼Œä¹Ÿè¢«æ€»ç»“ä¸º IPM ï¼ˆIntegral Probability Metricï¼‰</p>
  </li>
  <li>
    <p>\(Wasserstein \; GAN\) çš„ä¸€ä¸ªæ ¸å¿ƒæ€æƒ³å°±æ˜¯åˆ©ç”¨å¯¹å¶é—®é¢˜ï¼ŒæŠŠ \(\theta\) ä»çº¦æŸä¸­åŒ–å»ï¼Œé‚£ä¹ˆæ˜¯å¦æœ‰åœ¨å–åˆ«çš„ \(p\) çš„æƒ…å†µä¸‹ï¼Œæ˜¯å¦æœ‰åˆ«çš„å¯¹å¶å‘¢ï¼Ÿæœ‰çš„ï¼Œæ¯”å¦‚ Sobelev GAN å°±åˆ©ç”¨ \(p=2\) çš„æƒ…å†µæ¥è®¾è®¡ç®—æ³•ï¼š</p>
  </li>
</ol>

\[\sup _{f \in W^{1,2}(\mathcal{X}, \mu)} \mathbb{E}_{x \sim \mathbb{g_{\theta}}} f(x)-\mathbb{E}_{x \sim \mathbb{\mu_X}} f(x) \quad
   W^{1,2}(\mathcal{X}, \mu)=\left\{f: \mathcal{X} \rightarrow \mathbb{R}, \int_{\mathcal{X}}\left\|\nabla_{x} f(x)\right\|^{2} \mu(x) d x&lt;\infty\right\}\]

<h3 id="variational-autoencoder">Variational autoencoder</h3>

<h4 id="vanilla-vae">Vanilla-VAE</h4>

<p>å…³äº VAE çš„åŸºç¡€éƒ¨åˆ†ï¼Œå¯ä»¥çœ‹<a href="https://changhaowu.github.io/2021/01/25/Generative-Model-Part-2-A-Survey-on-Variational-Autoencoders/">è¿™ä¸€éƒ¨åˆ†</a>ä¸­å…³äº VAEçš„ä»‹ç»ï¼Œç°åœ¨å¼€å§‹ä»ç›´è§‰ä¸Šä»¿ç…§ autoencoder çš„ç»“æ„æ¥æ„é€  VAEï¼š</p>

\[\begin{array}{l}
\phi: \mathcal{X} \rightarrow \mathcal{F} \\
\psi: \mathcal{F} \rightarrow \mathcal{X} \\
\phi, \psi=\underset{\phi, \psi}{\arg \min }\|X-(\psi \circ \phi) X\|^{2}
\end{array}\]

<p>ç±»ä¼¼çš„ï¼Œåœ¨ VAE ä¸­ä¹Ÿæœ‰ä¸¤ä¸ªå¯¹åº”çš„è€¦åˆåˆ†å¸ƒï¼Œç”Ÿæˆåˆ†å¸ƒï¼ˆè§£ç å™¨ï¼‰\(p_{\theta}(x\mid z)\) å’Œæ¨æ–­åˆ†å¸ƒï¼ˆç¼–ç å™¨ï¼‰\(q_{\phi}(z\mid x)\)ï¼Œé‚£ä¹ˆé—®é¢˜å˜æˆäº†å¦‚ä½•ç”¨è¿™ä¸¤ä¸ªåˆ†å¸ƒæ„é€ åˆ†å¸ƒä¹‹é—´çš„å¤å»ºè¯¯å·®ï¼š</p>

<p>é¦–å…ˆæƒ³åˆ°çš„æ˜¯èƒ½åœ¨ VAE æ¡†æ¶ä¸‹æŠŠ \(p(x)\) è¡¨è¾¾å‡ºæ¥ï¼Œç„¶åç”¨ \(Wasserstein\) è·ç¦»åšå’Œç»éªŒåˆ†å¸ƒçš„æ¯”è¾ƒå˜›ï¼Ÿå¯æƒœå³ä½¿æ˜¯ VAEï¼Œä¸€æ ·åšä¸åˆ°è¿™æ ·çš„æ•ˆæœï¼Œä¾ç„¶å—åˆ¶äº intractability:</p>

\[p(x)=\int p_{\theta}(x \mid z) p_{z}(z) d z = \sum_1^n  p_{\theta}(x \mid z_i) p_{z}(z_i)\]

<p>ä½†æ˜¯ä¸Šå¼ä¸­ \(\int p_{\theta}(x \mid z) p_{z}(z) d z\)ï¼Œ å¯å‘æˆ‘ä»¬æ˜¯å¦èƒ½ç”¨æ¨æ–­åˆ†å¸ƒ \(q_{\phi}(z\mid x)\) ä½œä¸º \(p_{z}(z)\) çš„æ›¿ä»£å‘¢ï¼Ÿè¿™æ ·æŸç§æ„ä¹‰ä¸Šä¹Ÿä½“ç°äº†å¤å»ºçš„è¿‡ç¨‹ï¼Œå¯èƒ½ \(Evidence \; Lower \; Bound\) å°±æ˜¯å—æ­¤å¯å‘çš„ï¼š</p>

\[\begin{aligned}
\log p_{\boldsymbol{\theta}}(\mathbf{x}) 
&amp;=\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\log p_{\boldsymbol{\theta}}(\mathbf{x})\right] 
\\
&amp;=\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})}\right]\right]
\\
&amp;=\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})} \frac{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}{p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})}\right]\right]
\\
&amp;= \mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})} \frac{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}{p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})}\right]\right]
\\
&amp;= \underbrace{\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\right]\right]}_{=\mathcal{L}_{\boldsymbol{\theta}, \boldsymbol{\phi}}(\mathbf{x})\\(\mathrm{ELBO})}
+
\underbrace{\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}{p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})}\right]\right]}_{=D_{K L}\left(q_{\phi}(\mathbf{z} \mid \mathbf{x}) \| p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})\right)}

\end{aligned}\]

<p>è¿™ä¸€éƒ¨åˆ†è¿˜æ˜¯åˆ©ç”¨ MLE çš„æ€æƒ³å»åš \(\theta,\phi\) çš„ä¼˜åŒ–ï¼Œåé¢ä¼šç»™å‡ºä¸€ä¸ªä¸ç”šä¸¥è°¨è¯æ˜ï¼šMLE ä¸ \(\min_{\theta,\phi}Distance\) æ˜¯ç­‰ä»·çš„</p>

<p>æŠŠä¸Šå¼ä¸­çš„ç¬¬ä¸€éƒ¨åˆ†å–å‡ºæ¥ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ª \(\log p_{\theta}(\mathbf{x})\) çš„ä¸‹ç•Œï¼ŒåŒæ—¶è¿˜å¯ä»¥è¿›ä¸€æ­¥æ‹†è§£ï¼š</p>

\[\begin{aligned}
\mathrm{L}_{\theta, \phi}(\boldsymbol{x}) &amp;=\mathbb{E}_{\mathrm{q}_{\phi}(z \mid x)}\left[\log p_{\theta}(\boldsymbol{x} \mid \boldsymbol{z})+\log p_{\theta}(\boldsymbol{z})-\log \mathrm{q}_{\phi}(\boldsymbol{z} \mid \boldsymbol{x})\right] \\
&amp;=\mathbb{E}_{q_{\phi}(z \mid x)}\left[\log p_{\theta}(x \mid z)\right]-D_{K	 L}\left[q_{\phi}(z \mid x) \| p_{\theta}(z)\right]
\end{aligned}\]

<p>ä¸Šå¼ä¸­ç¬¬ä¸€éƒ¨åˆ†ä»£è¡¨å¤å»ºçš„è¯¯å·®ï¼Œç”±æ¨æ–­åˆ†å¸ƒç¼–ç æˆ \(z\) çš„ \(x\) ä¸æœ€åç”Ÿæˆåˆ†å¸ƒè§£ç çš„ \(x\) çš„è¯¯å·®è¶Šå°ï¼Œç¬¬ä¸€é¡¹è¶Šå¤§ï¼Œè€Œç¬¬äºŒéƒ¨åˆ†æ§åˆ¶æœ€åç”¨æ¥æŠ½æ ·çš„ \(p_{z}(z)\)  äºæ¨æ–­åˆ†å¸ƒ \(q_{\phi}(z \mid x)\) ç›¸å·®ä¸è¿œ</p>

<h4 id="wasserstein-vae">Wasserstein VAE</h4>

<p>é‚£ä¹ˆè¿˜æ˜¯å°è¯•ç”¨ç”¨ç”Ÿæˆåˆ†å¸ƒå»æ‹Ÿåˆç»éªŒåˆ†å¸ƒè¿™ä¸ªè§’åº¦æ¥çœ‹ VAE çš„è¿‡ç¨‹</p>
:ET