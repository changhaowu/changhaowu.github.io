I"F<ul class="table-of-content" id="markdown-toc">
  <li><a href="#generative-model-part-1intuition-on-latent-variable-generative-model" id="markdown-toc-generative-model-part-1intuition-on-latent-variable-generative-model">Generative Model Part 1:Intuition on Latent Variable Generative Model</a>    <ul>
      <li><a href="#intuitionevery-ml-problem-can-be-reduced-to-a-fitting-problem" id="markdown-toc-intuitionevery-ml-problem-can-be-reduced-to-a-fitting-problem">Intuition：Every ML problem can be reduced to a fitting problem</a></li>
      <li><a href="#why-latent-variable-model" id="markdown-toc-why-latent-variable-model">Why latent variable model?</a></li>
      <li><a href="#what-to-fit" id="markdown-toc-what-to-fit">What to fit?</a></li>
      <li><a href="#how-good-is-the-fit-" id="markdown-toc-how-good-is-the-fit-">How good is the fit ?</a>        <ul>
          <li><a href="#generative-adversarial-network" id="markdown-toc-generative-adversarial-network">Generative Adversarial Network</a>            <ul>
              <li><a href="#vanilla-gan" id="markdown-toc-vanilla-gan">Vanilla-GAN</a></li>
              <li><a href="#wasserstein-gan" id="markdown-toc-wasserstein-gan">Wasserstein-GAN</a></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="generative-model-part-1intuition-on-latent-variable-generative-model">Generative Model Part 1:Intuition on Latent Variable Generative Model</h1>

<p>为了以一种在直觉上更合理的形式去定义生成模型，在 <a href="https://changhaowu.github.io//2020/08/06/Generative-Model-Part-0-Theoretical-Basis-of-Generative-Model/">Generative Model Part 0：Theoretical Basis of Generative Model</a> 外再补充一篇 Generative Model Part 1:Intuition on Generative Model 使得生成模型的定义更加的复合直觉上的结果，而不是直接的扔出一堆结果</p>

<p>因为上述的原因，这一篇的叙事语言可能会有一些怪，就像辩论式的语言，这样的叙事方法是符合真理是越辩越明的想法，或者说，这一篇的叙事拟合了笔者在写这一篇时，头脑中两个小人在辩论 X)</p>

<h2 id="intuitionevery-ml-problem-can-be-reduced-to-a-fitting-problem">Intuition：Every ML problem can be reduced to a fitting problem</h2>

<p>在常规的机器模型问题中，我们常努力把问题归结到一种拟合问题上，这种拟合有很多种形式，比如判别模型可以理解成，用一个多层神经网络去学习一个拟合模型，在特征提取器（feature extractor）形成的像空间中，追求对于分离超平面的拟合，而生成模型 \(p_{\theta}\) 在最大似然函数下的定义：</p>

\[\theta^* = \arg\max \sum_i^n p_{\theta}(x_i)\]

<p>看吧，那么这个模型是在拟合什么呢？直觉上很难回答，那么这样定义下的生成模型在直觉上和一般的机器学习模型是产生了分歧的，那么下面尝试用 “拟合XX” 这样的想法来叙事生成模型，同时证明 “拟合XX” 的想法其实和最大似然原则下的模型是等价的</p>

<p>那么借鉴一些判别模型的构造，一个特征提取器 \(f_{\theta}\) ，一个分类器 \(h_{\phi}\) ，\(f_{\theta}\) 执行一个降维的过程，把高维数据流形降维到低维特征空间 \(\Im(f_{\theta})\) 中，进一步的，分类器 \(h_{\phi}\) 在特征空间 \(\Im(f_{\theta})\) 中寻找一个分离超平面，通过超平面判别输入的类别</p>

<p style="text-align: center;"><img src="/images/2021-05-01-Generative-Model-Part-1-Intuition-on-Generative-Model/illustration_of_discriminative_model.png" alt="illustration_of_discriminative_model" style="zoom:25%;" /></p>

<p>那么生成模型，或者说基于隐空间的生成模型，其想法是相反的，把低位隐空间中的无意义噪声映射到高维数据流形上，好像是只要一个生成映射 \(g_{\theta}\) 把从隐空间中采样的 \(z\) 映射到 \(g(\theta) \in X\) 中就好了（只要一个参数，事情少了一半），但是并不是，这是训练完的生成模型，但是为了训练生成模型，还需要另外一个参数 \(\phi\) ，“There‘s no silver bullet”</p>

<p style="text-align: center;"><img src="/images/2021-05-01-Generative-Model-Part-1-Intuition-on-Generative-Model/no-silver-bullet.png" alt="no-silver-bullet" style="zoom:50%;" /></p>

<h2 id="why-latent-variable-model">Why latent variable model?</h2>

<p>那么按照 “拟合XX” 的思路去构建模型，这件事情是分成两步的，拟合的目标以及拟合程度的度量</p>

<p>但是首先，再往前退一步，要确定是指导建立模型的思想，就是为什么可以通过隐空间构造生成模型这件事情，这是不显然的，有些困惑的，比如拿一个 \(28 \times 28\) 的 \(\textit{minst}\) 字体来说，一种自然的想法当然是：</p>

\[p(x)=\prod_{i=1}^{D} p\left(x_{i} \mid x_{&lt;i}\right)\]

<p>而不是通过隐空间构造的：</p>

\[p(x)=\int p_{\theta}(x \mid z) p_{z}(z) d z = \sum_1^n  p_{\theta}(x \mid z_i) p_{z}(z_i)\]

<p>下面那个隐空间的想法甚至都无法顺利的计算（隐空间采样到底多少是合适的呢？）</p>

<p>上面那个分解也是能做的，但是看这个分解就知道，它严重的违反了设计深度学习算法所需要的并行计算的过程，这会导致其计算缓慢</p>

<p>更重要的是，根据隐空间建模这件事情符合一些实验中观察到的事实同时又降低了模型的复杂度：</p>

<ol>
  <li>
    <p>比如 \(28 \times 28\) 的 \(\textit{minst}\) 字体来说，由于实验上可知，通过判别模型可以对数据进行很好的分类，以tensorflow core提供的网络为例，从特征提取器输出的维度是128维，比起原来的784维小了很多，更不遑论更深的网络，提取器输出的维度比128维还要小很多，这种现象被总结成流形分布律：比起弥散在整个空间中，同源同类的数据更倾向于分布在一个高维流形附近，这支持我们去训练一个复杂度更低的网络，更少的训练量，达到的拟合效果是差不多的</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()</span>
       
    <span class="c1">### just one layer convolution, the complexity of model ###  &lt;- Here!!
</span>       
    <span class="bp">self</span><span class="p">.</span><span class="n">d1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">d2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
   
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">d1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">d2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
   
<span class="c1"># Create an instance of the model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>那么换一种思路，从仿生的角度来说，我们平时写一个数字，脑子里真的想了784件独立的事情嘛？相反，我们可能考虑笔顺如何？弯折如何？这样的更抽象的事情，而不是思考784个pixel是不是要涂黑。进一步的，若是放大这个数字 \(2\times2\) 倍，难道我们想的事情会多4倍嘛？</p>
  </li>
</ol>

<p>因此，通过隐空间来建模生成模型，既有硬件计算上的好处，同时又符合观察到的实验现象，那么好话说完了，该说不好的了，正如之前所说的：</p>

\[p(x)=\int p_{\theta}(x \mid z) p_{z}(z) d z\]

<p>这个式子在计算上是intractability，那么就需要通过绕路的办法来建模遵循隐空间想法的生成模型</p>

<h2 id="what-to-fit">What to fit?</h2>

<p>根据 “要学习一个好的生成映射” 这件事情来建立一个拟合的目标，仿照之前的判别模型的建立，分成两步来做：</p>

<p>那么如何确定这两步呢？GAN（Generative Adversarial Network）和 VAE （Varaitional Autoencoder）分别提供了两种思路：</p>

<ol>
  <li>GAN：最后要的是一个好的生成映射，而不是一个真实的数据分布，那么直接追求好的生成映射。第一步通过生成映射 \(G\) 把隐空间采样映射到高维空间中，第二步通过真实数据训练一个度量 \(D\) ，来度量”有多像从数据集中采样的数据”，这样的两步来设计算法</li>
  <li>VAE：那么既然有隐空间的想法支持，不妨仿照autoencoder的想法，建立隐空间概率分布和数据空间概率分布的关系，比起GAN放弃了对分布的把握，VAE保留了这一点，在训练过程中，通过编码器 \(p_{\theta}\) 和解码器 \(q_{\phi}\) 来模仿复建的过程，最后从训练好的生成分布中采样，这样的两步来设计算法</li>
</ol>

<p>画图来说的话就是如下所示：</p>

<p style="text-align: center;"><img src="/images/2021-05-01-Generative-Model-Part-1-Intuition-on-Generative-Model/two_step_GAN_VAE.png" alt="two_step_GAN_VAE" style="zoom:30%;" /></p>

<p>但是这样看的话，两者在结构上就似乎毫无关系，为了更好的统一起来，需要更高一些的观点，在数据流形拟合这个共同目标下，就能被统一起来：</p>

<p style="text-align: center;"><img src="/images/2021-05-01-Generative-Model-Part-1-Intuition-on-Generative-Model/data_manifold_fit.png" alt="data_manifold_fit" style="zoom:30%;" /></p>

<p>两者都是从隐空间出发，解码器 \(p_{\theta}\) 和生成映射 \(G\) 的作用是类似的，但是区别在于为了度量生成映射 \(G\)，GAN的第二部分需要一个判别器，而相对应的，VAE直接使用原来数据空间中的测度把解码器分布 \(p_{\theta}\) 经验分布比较即可，但是建立隐空间的分布和数据空间的分布之间的双向关系，需要相应的训练一个编码器分布 \(q_{\phi}\)</p>

<h2 id="how-good-is-the-fit-">How good is the fit ?</h2>

<p>有了拟合的目标（把数据流形和经验分布进行拟合），就需要去建立衡量拟合程度的指标：</p>

<h3 id="generative-adversarial-network">Generative Adversarial Network</h3>

<p>由于GAN自带一个判别器充当度量，那么现在要做的就是通过判别器 \(D\) 来衡量数据分布 \(p_{data}\) 和 \(p_{G}\) 之间的距离</p>

<h4 id="vanilla-gan">Vanilla-GAN</h4>

<p>在vanilla-GAN中，goodfellow是利用一种计数的思想，构造了一个损失函数，同时证明了构造的损失函数在优化过程中是对于 Jenson-Shannon divergence 的一个逼近：</p>

<p>那么首先从直觉上构造损失函数，我希望判别器提升的话，那么就是分辨的出生成器中出来数据，同时不误判真实的数据，同时生成器要能够尽可能的使生成数据被误认为真实数据：
\(\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\mathrm{data}}(\boldsymbol{x})}[D(\boldsymbol{x})]+\mathbb{E}_{\mathbf{z} \sim p_{\boldsymbol{z}}(\mathbf{z})}[1-D(G(\mathbf{z}))]\)
那么这样的损失函数是可以做到要求的，为了不失模型的泛化性，改写成：
\(\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\mathrm{data}}(\boldsymbol{x})}[f(D(\boldsymbol{x}))]+\mathbb{E}_{\mathbf{z} \sim p_{\boldsymbol{z}}(\mathbf{z})}[f(1-D(G(\mathbf{z}))]\)
这样的判别函数当然是符合直觉的，但是在符合直觉的同时，我们希望在理论给予支撑，换言之，如果这个模型是某种分布的距离的逼近，这样是才是符合理论的方法，而 Vanilla-GAN 中也证明了这一点：</p>

<ol>
  <li>
    <p>首先固定生成器 \(G\)，去求出最优的判别器 \(D\)：
\(\begin{aligned}
V(G, D) &amp;=\int_{\boldsymbol{x}} p_{\text {data }}(\boldsymbol{x}) \log (D(\boldsymbol{x})) d x+\int_{\boldsymbol{z}} p_{\boldsymbol{z}}(\boldsymbol{z}) \log (1-D(g(\boldsymbol{z}))) d z \\
&amp;=\int_{\boldsymbol{x}} p_{\text {data }}(\boldsymbol{x}) \log (D(\boldsymbol{x}))+p_{g}(\boldsymbol{x}) \log (1-D(\boldsymbol{x})) d x
\end{aligned}\)
由于 \(y \rightarrow a \log (y)+b \log (1-y)\) 在 \([0,1]\) 上在 \(\frac{a}{a+b}\) 取到最优，因此最优的判别器是 \(\frac{p_{\text {data }}(x)}{P_{\text {data }}(x)+p_{g}(x)}\)</p>
  </li>
  <li>
    <p>在此之上固定判别器 \(D\)，这其实能够充当一个距离 \(D(p_{g},p_{data})\)：
\(\begin{aligned}
D(p_{g},p_{data})&amp;=\max _{D} V(G, D) \\
&amp;=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}}\left[\log \left(1-D_{G}^{*}(G(\boldsymbol{z}))\right)\right] \\
&amp;=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \left(1-D_{G}^{*}(\boldsymbol{x})\right)\right] \\
&amp;=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log \frac{p_{\text {data }}(\boldsymbol{x})}{P_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \frac{p_{g}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right]
\\
&amp; = -\log (4)+K L\left(p_{\text {data }} \| \frac{p_{\text {data }}+p_{g}}{2}\right)+K L\left(p_{g} \| \frac{p_{\text {data }}+p_{g}}{2}\right)
\\
&amp; = -\log (4)+2 \cdot J S D\left(p_{\text {data }} \| p_{g}\right)
\end{aligned}\)</p>
  </li>
</ol>

<p>那么说明vanilla-GAN在训练过程中本身就是在拟合一个 \(JS\) 散度</p>

<h4 id="wasserstein-gan">Wasserstein-GAN</h4>

<p>那么现在回到散度本身，无论是 \(KL\) 散度抑或是 \(JS\) 散度，都可以统一在 \(f-divergence\) 下，且 \(f-divergence\) 可以充当一个分布之间的距离：</p>

<p>\(D_{f}(P \| Q) \equiv \int_{\Omega} f\left(\frac{d P}{d Q}\right) d Q\)
并且有以下约束：</p>

<ol>
  <li>\(f\)  是凸函数且 \(f(1)=0\)</li>
  <li>\(P\) 在 \(Q\) 的意义下，在 \(\Omega\) 上连续</li>
</ol>

<p>那么先回到之前vanilla-GAN中定义的 \(p_{data}\) ，这个是真实数据分布，这只能说明 \(p_{data}\) 是存在的，而没有提供给我们一个如何 \(p_{data}\) 的办法，那么如何对于 \(p_{data}\) 做一个合理的逼近呢？</p>

<p>经验分布函数可能是一个合理的选择，有数据集 \(X=\left\{x_{1}, x_{2}, \ldots, x_{n}\right\}\)，通过 \(\delta\) 函数定义经验分布函数：
\(\mu_{X}(x)=\frac{1}{n} \sum_{i=1}^{n} \delta x_{i}(x)\)
那么当采样足够多的时候，经验分布函数是可以逼近数据分布 \(p_{data}\) 的</p>

<p>那么问题就可以转化成，现在要训练一个生成模型 \(g_{\theta}\)，去优化 \(Distance(g_{\theta},\mu_{X})\) ，比起之前所说的比较抽象的拟合数据分布，这样就跟切实了</p>

<p>\(f-divergence\) 在 \(\mu_{X}(x)\) 下就产生了定义上的问题，因为 \(\mu_{X}\) 是一个离散的分布，\(supp(\mu_{X}) = \left\{x_{1}, x_{2}, \ldots, x_{n}\right\}\) ，在此之外的部分无法去计算  \(Distance(g_{\theta},\mu_{X})\) ，这样的话就无法用来有效进行 SGD ，那么基于逼近 \(JS-divergence\) 的 vanilla-GAN 会出现难以训练的问题也是正常的了</p>

<p>在这样的背景下，去找一个能够有效计算 \(Distance(g_{\theta},\mu_{X})\) 的距离也就不奇怪了，\(Wasserstein\) 距离呼之欲出，关于 \(Wasserstein\) 距离的基础部分 <a href="https://changhaowu.github.io/2021/01/20/Optimal-Transport-Note-Part-1/">最优传输</a></p>

<p>那么在这个框架下审视 \(Wasserstein \; GAN\)：
\(W_{p}(g_{\theta},\mu_{X}):=\left(\inf _{\gamma \in \Gamma(g_{\theta},\mu_{X})} \int_{X \times X} d(x, y)^{p} \mathrm{~d} \gamma(x, y)\right)^{1 / p}\)
可以把约束通过拉格朗日函数写出来：</p>
:ET