I"Q<ul class="table-of-content" id="markdown-toc">
  <li><a href="#analytical-function-case" id="markdown-toc-analytical-function-case">Analytical Function Case</a></li>
  <li><a href="#intermediated-states-case" id="markdown-toc-intermediated-states-case">Intermediated States Case</a></li>
  <li><a href="#ode-controlled-case" id="markdown-toc-ode-controlled-case">ODE controlled Case</a></li>
</ul>
<p>Adjoint States Methods 在数值计算中非常的有用，其在1960年代由 Pontryagin 提出以更高效的计算梯度，在如地震学，冰川学等学科的数值模拟中广泛应用，而近来神经网络的优化问题范式同样符合 Adjoint States Methods 使用范畴，当在神经网络中使用时，他还有个更有名的名字 ‘Back Propagation’，更巧妙的是，在 NIPS 2018 best paper winner ‘Neural Ordinary Differential Equations’ 中，Adjoint States Methods 的应用使得梯度对于内存的计算复杂度从 O(n) 降至 O(1)，换言之，从要把整个网络的计算图存下来的一般 Back Propagation, Adjoint States Methods 把梯度下降变成了一个逐层迭代求解的问题</p>

<p>于是现在优化问题的定义开始，现在有输入 $x \in \mathbb{R}^{n_{x}}$，控制 $p \in \mathbb{R}^{n_{p}}$, 有优化问题：</p>

\[\arg_{p} \min J(x, p) \ \ \ J: \mathbb{R}^{n_{x}} \times \mathbb{R}^{n_{p}} \rightarrow \mathbb{R}
\\
s.t \ \ \ f(x, p)=0  \ \ \ f: \mathbb{R}^{n_{x}} \times \mathbb{R}^{n_{p}} \rightarrow \mathbb{R}^{n_{x}}\]

<p>如果以神经网络的视角来看的话，$J$ 即代表损失函数，而控制 $p$ 其实就是控制网络的参数，逐层来定义网络中的 hidden layers</p>

<p>为了对研究的情况做一些分类， 可以从 $J(x, p)$ 的角度来看，在 ‘16-90-computational-methods-in-aerospace-engineering’ 中， Qiqi Wang 教授定义了五种情况：</p>

<ol>
  <li>
    <p>解析的 $J(x, p)$，这样直接计算即可</p>
  </li>
  <li>
    <p>存在 intermediate state 的 $x_i$ 的 $J(x_i, p)$​, 神经网络就属于这种情况</p>

\[x_{n}=x_{n}\left(x_{n-1}, p\right)
\\
x_{0}=x_{0}(p)\]
  </li>
  <li>
    <p>$x$ 由一个ODE控制</p>

\[J(x(t), p)   \ \ \    s.t \ \frac{d x}{d t}=f(x, p)\]
  </li>
  <li>
    <p>$x,p$ 由一个隐函数 $f(x, p)=0$ 控制</p>
  </li>
  <li>
    <p>$x$ 由一个PDE控制, $J(x(y,t), p) $</p>
  </li>
</ol>

<p>下文的行文结构做如此安排：通过第一种情况来叙述 Adjoint States Method 的思想，通过第二种情况来展现 Back Propagation 和 Adjoint States Method 的等价性，通过第三种情况来分析 Neural ODEs 中利用 Adjoint States Method 来减少计算内存复杂度的方法</p>

<h3 id="analytical-function-case">Analytical Function Case</h3>

<p>通过定义拉格朗日函数 $\mathcal{L}(x, p, \lambda) \equiv J(x,p)+\lambda^{T} f(x, p)$， 同时由于 $f(x, p) = 0$, 可知 $x = x(p)$，这样可以化代价函数 $J(x,p)$ 为 $J(x(p))$</p>

\[\begin{aligned} 
\mathrm{d}_{p} f(x)=\mathrm{d}_{p} \mathcal{L} &amp;=\partial_{x} J \mathrm{~d}_{p} x+\mathrm{d}_{p} \lambda^{T} f+\lambda^{T}\left(\partial_{x} f \mathrm{~d}_{p} x+\partial_{p} f\right) 
\\
&amp;=J_{x} x_{p}+ \lambda^{T}\left(f_{x} x_{p}+f_{p}\right) \quad \text { because } f=0 \text { everywhere }
\\ 
&amp;=\left(J_{x}+\lambda^{T} f_{x}\right) x_{p}+\lambda^{T} f_{p}  
\end{aligned}\]

<p>为了方便计算 $d_p f $，其中 $f_{p},J_{p}$ 都是可以直接解析计算的，而 $x_{p}$ 则需要通过整个网络迭代重新计算，为了计算梯度的便捷性，得到了拉格朗日乘子 $f_{x}^{T} \lambda=-J_{x}^{T}$，那么 $d_p J=\lambda^{T} f_p $</p>

<p>而 $\lambda = -(f_{x}^{-1})^{T}J_{x}^{T}$ ，这种共轭转置被称为 adjoint variable，这也是这样计算梯度的方法被称为 adjoint state method 的原因</p>

<h3 id="intermediated-states-case">Intermediated States Case</h3>

<p>现在有如下计算图:</p>

<p style="text-align: center;"><img src="/images/2021-12-07-Adjoint-Methods-and-Auto-Differentiation/intermediate_states_graph.png" alt="intermediate_states_graph" style="zoom:40%;" /></p>

<p>通过 BP 算法我们已经知道了 $d_p J$ 的形式了，而通过 adjoint method 可以得到同样的结果：</p>

<p>神经网络逐层转播的过程可以形成如下约束</p>

\[\left\{\begin{array}{l}
x_{0}=x_{0}(p) \\
x_{i}=x_{i}\left(x_{i-1}, p\right)
\end{array}\right.\]

<p>于是有拉格朗日函数</p>

<p>$L(x, p, \lambda)=J\left(x_{n}\right)+\lambda_{n}^{T}\left(x_{n}-x_{n}\left(x_{n-1}, p\right)\right)+\cdots+\lambda_{1}^{\top}\left(x_{1}-x_{1}\left(x_{0}, p\right)\right)+\lambda_{0}^{\top}\left(x_{0}-x_{}\left(p\right)\right) $</p>

<p>对其做扰动，可以得到</p>

\[\begin{aligned} 
\delta L=\frac{\partial J}{\partial x_{n}} \delta x_{n} &amp;+\lambda_{n}^{T}\left(\delta x_{n}-\frac{\partial x_{n}}{\partial x_{n-1}} \delta x_{n-1}-\frac{\partial x_{n}}{\partial p} \delta p\right) 
\\ &amp;+\lambda_{n-1}^{T}\left(\delta x_{n-1}-\frac{\partial x_{n-1}}{\partial x_{n-2}} \delta x_{n-2}-\frac{\partial x_{n-1}}{\partial p} \delta p\right) 
\\ &amp;+\cdots 
\\ &amp;+\lambda_{0}^{T}\left(\delta x_{0} + \frac{d x_{0}}{d p} \delta p\right).
\end{aligned}\]

<p>类似最简单情况的想法，为了减少后续计算 $\frac{\partial L}{\partial p}$ 的计算量，需要把反复计算的 $\delta x_{i}$ 消去，由此得到了关于各个 $\lambda_{i}^{T}$ 的约束，代入并消去多余项后有：</p>

\[\frac{\partial J}{\partial p}=\sum_{i }\frac{\partial E}{\partial x_i} \frac{\partial x_i}{\partial p}\]

<h3 id="ode-controlled-case">ODE controlled Case</h3>

<p>这种对偶求解梯度的方法在特殊情况下会有意料之外的效果，在前 面两节我们证明了这种对偶方法求解的结果和原问题求解的梯度是等价的，而在这节中，借助特殊情况的约束函数 $f(x, p) = 0$，adjoint method 在特殊情况下展现出了比原问题求梯度更加优秀的数值计算性质</p>

<p>由于考虑到ODE的约束 $\frac{d z}{d t}=f_{\theta}(s, x, z)$，其中 $s$ 为网络深度的输入，参数 $\theta$ 为网络的控制， 则很自然的使用一个对时间积分的约束，写出拉格朗日函数：
\(L:=J-\int_{0} \mathbf{a}^{\top}(\tau)\left[\dot{\mathbf{z}}(\tau)-f_{\theta}\left(s, \mathbf{x}, \mathbf{z}(\tau)\right)\right] \mathrm{d} \tau\)
由于构造的拉格朗日乘子，类似之前的情况，$\mathrm{d} \mathcal{L} / \mathrm{d} \theta=\mathrm{d} \ell / \mathrm{d} \theta$，展开上式：
\(\begin{aligned} \mathcal{L} &amp;=\ell-\left.\mathbf{a}^{\top}(\tau) \mathbf{z}(\tau)\right|_{0} ^{S}+\int_{0}^{S}\left(\dot{\mathbf{a}}^{\top} \mathbf{z}+\mathbf{a}^{\top} f_{\theta}\right) \mathrm{d} \tau \\ &amp;=L(\mathbf{z}(S))-\left.\mathbf{a}^{\top}(\tau) \mathbf{z}(\tau)\right|_{0} ^{S}+\int_{0}^{S}\left(\dot{\mathbf{a}}^{\top} \mathbf{z}+\mathbf{a}^{\top} f_{\theta}+l\right) \mathrm{d} \tau \end{aligned}\)
计算上式的梯度：
\(\begin{aligned} \frac{\mathrm{d} \ell}{\mathrm{d} \theta} &amp;=\frac{\mathrm{d} \mathcal{L}}{\mathrm{d} \theta}=\frac{\partial L(\mathbf{z}(S))}{\partial \mathbf{z}(S)} \frac{\mathrm{d} \mathbf{z}(S)}{\mathrm{d} \theta}-\mathbf{a}^{\top}(S) \frac{\mathrm{d} \mathbf{z}(S)}{\mathrm{d} \theta}-\mathbf{a}^{\top}(0) \frac{\mathrm{d} \mathbf{z}(0)}{\mathrm{d} \theta} \\ &amp;+\int_{0}^{S}\left[\dot{\mathbf{a}}^{\top} \frac{\mathrm{d} \mathbf{z}}{\mathrm{d} \theta}+\mathbf{a}^{\top}\left(\frac{\partial f_{\theta}}{\partial \theta}+\frac{\partial f_{\theta}}{\partial \mathbf{z}} \frac{\mathrm{d} \mathbf{z}}{\mathrm{d} \theta}+\frac{\partial f_{\theta}}{\partial \mathbf{x}} \frac{\mathrm{d} \mathbf{x}}{\mathrm{d} \theta}+\frac{\partial f_{\theta}}{\partial \tau} \frac{\mathrm{d} f}{\partial \theta}\right)+\frac{\partial l}{\partial \mathbf{z}} \frac{\mathrm{d} \mathbf{z}}{\mathrm{d} \theta}+\frac{\partial l}{\partial \tau} \frac{\mathrm{d} f}{\mathrm{~d} \theta}\right] \mathrm{d} \tau \end{aligned}\)
整理得到了</p>
:ET