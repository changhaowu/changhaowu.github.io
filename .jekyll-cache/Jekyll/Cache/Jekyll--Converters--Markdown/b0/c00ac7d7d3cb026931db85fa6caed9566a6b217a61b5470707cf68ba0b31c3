I"â<ul class="table-of-content" id="markdown-toc">
  <li><a href="#frequency-fourier-and-galerkin" id="markdown-toc-frequency-fourier-and-galerkin">Frequency Fourier and Galerkin</a>    <ul>
      <li><a href="#low-frenquency-and-function-space" id="markdown-toc-low-frenquency-and-function-space">Low Frenquency and Function Space</a></li>
      <li><a href="#galerkin-basis-road-to-application-in-neural-network" id="markdown-toc-galerkin-basis-road-to-application-in-neural-network">Galerkin basis, Road to application in Neural Network?</a></li>
    </ul>
  </li>
  <li><a href="#reference" id="markdown-toc-reference">Reference</a></li>
</ul>
<h2 id="frequency-fourier-and-galerkin">Frequency Fourier and Galerkin</h2>

<p>ä¸ºäº†åˆ°è¾¾å¯¹äº Neural ODE çš„æ›´æ·±å…¥çš„ç†è§£ï¼Œéœ€è¦è·³å‡ºæ®‹å·®æ–¹ç¨‹çš„çº¦æŸï¼ŒæŠŠæ¯å±‚ç¥ç»ç½‘ç»œéƒ½çœ‹ä½œä¸€ä¸ªç®—å­ï¼Œäºæ˜¯å¯ä»¥å’Œ PDE è”ç³»åˆ°ä¸€èµ·ï¼Œåˆ©ç”¨ PDE ä¸­å·²æœ‰çš„ä¸°å¯Œçš„æ–¹æ³•å’Œç†è®ºæ¥è¾…åŠ©ä¼˜åŒ–ç¥ç»ç½‘ç»œã€‚æœ¬æ–‡çš„å›¾æ–‡èµ„æ–™æ¥æºäº <a href="http://arxiv.org/abs/1901.06523">Frequency Principle: Fourier Analysis Sheds Light on Deep Neural Networks</a> å’Œè®¸å¿—é’¦è€å¸ˆå…³äº Frequency Principle çš„</p>

<p>è®²åº§ï¼Œä»¥åŠ  <a href="http://alice.loria.fr/index.php/bruno-levy.html">Bruno Levy</a> æ•™æˆå…³äº <a href="http://www.gretsi.fr/peyresq12/documents/3-maillage4.pdf">Function Space</a> çš„è®²åº§ä»¥åŠç»´åŸºç™¾ç§‘æä¾›çš„è¯¦å°½èµ„æ–™</p>

<h3 id="low-frenquency-and-function-space">Low Frenquency and Function Space</h3>

<p>Generally speaking, â€œFrequencyâ€ in pixels image corresponds to the rate of change of intensity across neighbouring pixels. ç”±æ­¤ä¸ºåŸºç¡€ï¼ŒæŠŠå›¾ç‰‡é€šè¿‡å‚…ç«‹å¶å˜æ¢è¿ç§»åˆ°é¢‘åŸŸåæ»¤æ‰é«˜é¢‘éƒ¨åˆ†æ¥é™å™ªç­‰å¾—åˆ°äº†ç†è®ºä¿è¯ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º</p>

<p style="text-align: center;"><img src="/images/2021-12-25-Frequency-Fourier-Galerkin/Image_frequency.png" alt="Image_frequency" style="zoom:50%;" /></p>

<p>å›¾åƒé‡Œ</p>

<h3 id="galerkin-basis-road-to-application-in-neural-network">Galerkin basis, Road to application in Neural Network?</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CVAE</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
  <span class="s">"""Convolutional variational autoencoder."""</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CVAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span>
                <span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span>
                <span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="c1"># No activation
</span>            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span> <span class="o">+</span> <span class="n">latent_dim</span><span class="p">),</span>
        <span class="p">]</span>

  <span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span>
  <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">eps</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">eps</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">latent_dim</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">apply_sigmoid</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>


</code></pre></div></div>

<p>####</p>

<h2 id="reference">Reference</h2>

<p>[1] C.-C. Jay Kuo <a href="https://arxiv.org/abs/1609.04112">Understanding Convolutional Neural Networks with A Mathematical Model</a></p>
:ET