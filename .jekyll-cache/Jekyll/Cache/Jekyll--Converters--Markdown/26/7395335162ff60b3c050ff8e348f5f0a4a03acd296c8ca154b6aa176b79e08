I"Ô.<ul class="table-of-content" id="markdown-toc">
  <li><a href="#frequency-fourier-and-galerkin" id="markdown-toc-frequency-fourier-and-galerkin">Frequency Fourier and Galerkin</a>    <ul>
      <li><a href="#low-frenquency-and-function-space" id="markdown-toc-low-frenquency-and-function-space">Low Frenquency and Function Space</a>        <ul>
          <li><a href="#low-frequency-basis-is-adequate-for-fitting" id="markdown-toc-low-frequency-basis-is-adequate-for-fitting">Low Frequency basis is adequate for fitting</a></li>
          <li><a href="#whats-function-space" id="markdown-toc-whats-function-space">Whatâ€™s function space</a></li>
        </ul>
      </li>
      <li><a href="#fourier-transform-and-application" id="markdown-toc-fourier-transform-and-application">Fourier Transform and Application</a></li>
      <li><a href="#galerkin-basis-road-to-application-in-neural-network" id="markdown-toc-galerkin-basis-road-to-application-in-neural-network">Galerkin basis, Road to application in Neural Network?</a></li>
    </ul>
  </li>
  <li><a href="#reference" id="markdown-toc-reference">Reference</a></li>
</ul>
<h2 id="frequency-fourier-and-galerkin">Frequency Fourier and Galerkin</h2>

<p>ä¸ºäº†åˆ°è¾¾å¯¹äº Neural ODE çš„æ›´æ·±å…¥çš„ç†è§£ï¼Œéœ€è¦è·³å‡ºæ®‹å·®æ–¹ç¨‹çš„çº¦æŸï¼ŒæŠŠæ¯å±‚ç¥ç»ç½‘ç»œéƒ½çœ‹ä½œä¸€ä¸ªç®—å­ï¼Œäºæ˜¯å¯ä»¥å’Œ PDE è”ç³»åˆ°ä¸€èµ·ï¼Œåˆ©ç”¨ PDE ä¸­å·²æœ‰çš„ä¸°å¯Œçš„æ–¹æ³•å’Œç†è®ºæ¥è¾…åŠ©ä¼˜åŒ–ç¥ç»ç½‘ç»œã€‚æœ¬æ–‡çš„å›¾æ–‡èµ„æ–™æ¥æºäº <a href="http://arxiv.org/abs/1901.06523">Frequency Principle: Fourier Analysis Sheds Light on Deep Neural Networks</a> å’Œè®¸å¿—é’¦è€å¸ˆå…³äº Frequency Principle çš„</p>

<p>è®²åº§ï¼Œä»¥åŠ  <a href="http://alice.loria.fr/index.php/bruno-levy.html">Bruno Levy</a> æ•™æˆå…³äº <a href="http://www.gretsi.fr/peyresq12/documents/3-maillage4.pdf">Function Space</a> çš„è®²åº§ä»¥åŠç»´åŸºç™¾ç§‘æä¾›çš„è¯¦å°½èµ„æ–™</p>

<h3 id="low-frenquency-and-function-space">Low Frenquency and Function Space</h3>

<h4 id="low-frequency-basis-is-adequate-for-fitting">Low Frequency basis is adequate for fitting</h4>

<p>Generally speaking, â€œFrequencyâ€ in pixels image corresponds to the rate of change of intensity across neighbouring pixels. ç”±æ­¤ä¸ºåŸºç¡€ï¼ŒæŠŠå›¾ç‰‡é€šè¿‡å‚…ç«‹å¶å˜æ¢è¿ç§»åˆ°é¢‘åŸŸåæ»¤æ‰é«˜é¢‘éƒ¨åˆ†æ¥é™å™ªç­‰å¾—åˆ°äº†ç†è®ºä¿è¯ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º</p>

<p style="text-align: center;"><img src="/images/2021-12-25-Frequency-Fourier-Galerkin/Image_frequency.png" alt="Image_frequency" style="zoom:35%;" /></p>

<p>å·¦å›¾åªæœ‰ä¸€ç§é¢œè‰²ï¼Œæ‰€æœ‰çš„åƒç´ ä¹‹é—´æ²¡æœ‰å˜åŒ–ï¼Œå› æ­¤åªæœ‰ä½é¢‘ä¿¡å·ï¼Œç„¶è€Œä»è‡ªç„¶ä¸­æ‹æ‘„çš„å³å›¾ä¸­ï¼Œä¸ºäº†è¡¨ç¤ºå„ç‰©ä½“ä¹‹é—´çš„å·®åˆ«ï¼Œç‰©ä½“çš„è¾¹ç¼˜å­˜åœ¨ç€edgeï¼Œå„ä¸ªç‰©ä½“çš„é¢œè‰²ä¹Ÿä¸å°½ç›¸åŒï¼Œåƒç´ ä¹‹é—´å­˜åœ¨ç€å˜åŒ–ï¼Œåˆ™æœ€åå›¾åƒä¸­å°±æœ‰æ¯”è¾ƒé«˜é¢‘çš„éƒ¨åˆ†ï¼Œè€Œå…¶ä¸­æœ€æç«¯çš„æƒ…å†µåˆ™ä¸ºåœ¨ä¸€å¼ ç™½çº¸ä¸Šï¼Œç›´æ¥ç”¨é»‘ç¬”ç”»ä¸€æ¡ç«–çº¿ï¼Œå°±ä¼šäº§ç”Ÿæœ€é«˜é¢‘çš„æƒ…å†µï¼š</p>

<p style="text-align: center;"><img src="/images/2021-12-25-Frequency-Fourier-Galerkin/black_line_in_white_paper.png" alt="black_line_in_white_paper" style="zoom:45%;" /></p>

<p>å¾ˆè‡ªç„¶çš„å¯ä»¥æƒ³åˆ°ï¼Œé«˜é¢‘çš„éƒ¨åˆ†ä¸­æœ‰å¾ˆå¤šçš„å™ªå£°ï¼ŒåŒæ—¶ä½é¢‘çš„éƒ¨åˆ†å™ªå£°åˆ™ç›¸å¯¹è¾ƒå°‘ï¼Œå¦‚æœä»å‡½æ•°æ‹Ÿåˆçš„è§’åº¦å»çœ‹é«˜é¢‘ä½é¢‘éƒ¨åˆ†ï¼Œåˆ™ä¼šæœ‰æ›´è´´è¿‘ç¥ç»ç½‘ç»œçš„ç»“è®ºå‡ºç°ï¼š</p>

<p style="text-align: center;"><img src="/images/2021-12-25-Frequency-Fourier-Galerkin/spatial_domain.gif" alt="fourier_domain" style="zoom:100%;" /></p>

<p>ä¸Šå›¾æ˜¯æŒ‰ç…§è®­ç»ƒæ—¶é—´çš„å…ˆåé¡ºåºæ¥å±•ç¤ºçš„ï¼Œå› æ­¤å½“è¦å»æ‹Ÿåˆä¸€ä¸ªå‡½æ•°çš„æ—¶å€™ï¼Œé¦–å…ˆå­¦ä¹ åˆ°çš„ä¿¡å·æ€»æ˜¯ä½é¢‘çš„ï¼Œè¿™äº›ä¿¡å·å­¦ä¹ çš„æ˜¯è¦å»æ‹Ÿåˆå‡½æ•°çš„ landscapeï¼Œç„¶åå†æ˜¯åˆ°çš„ detail éƒ¨åˆ†, landscape å’Œ detailï¼Œè¿™ä¸å°±æ°æ°å¯¹åº”ç€ä¹‹å‰çš„å›¾ç‰‡ä¸­ä½é¢‘ä¿¡å·å’Œé«˜é¢‘ä¿¡å·çš„å…³ç³»å˜›ã€‚</p>

<p style="text-align: center;"><img src="/images/2021-12-25-Frequency-Fourier-Galerkin/fourier_domain.gif" alt="fourier_domain" style="zoom:100%;" /></p>

<p>åœ¨ä¸Šå›¾å‚…ç«‹å¶åŸŸä¸Šçš„å¯è§†åŒ–æ›´å¥½çš„å±•ç°äº†è¿™ä¸ªç»“è®ºï¼Œå› æ­¤ç¥ç»ç½‘ç»œå­¦ä¹ æ—¶ï¼Œé¦–å…ˆå­¦åˆ°çš„æ˜¯ä½é¢‘çš„ä¿¡å·ï¼Œç„¶åå†æ˜¯é«˜é¢‘çš„ä¿¡å·ï¼Œè€Œä¹‹å‰ä»å›¾ç‰‡é‡Œå¾—åˆ°çš„ç»“è®ºæ˜¯ï¼Œé«˜é¢‘ä¿¡å·å¾€å¾€å¯¹åº”ç€å™ªå£°ï¼Œé‚£ä¹ˆå‡½æ•°æ‹Ÿåˆä¸­éšç€è®­ç»ƒçš„æ·±å…¥ï¼Œå¾—åˆ°çš„è¿‡æ‹Ÿåˆçš„æƒ…å†µæ˜¯å¦èƒ½ç†è§£æˆï¼Œæ‹Ÿåˆå™¨è¿‡åº¦å­¦ä¹ äº†æ ·æœ¬é›†ä¸­çš„å™ªå£°ï¼Œå¯¼è‡´äº†æ³›åŒ–æ€§èƒ½çš„ä¸‹é™å‘¢ï¼Ÿ</p>

<p style="text-align: center;"><img src="/images/2021-12-25-Frequency-Fourier-Galerkin/Typical-relationship-for-capacity-and-generalization-error.jpeg" alt="Typical-relationship-for-capacity-and-generalization-error" style="zoom:80%;" /></p>

<p>é‚£ä¹ˆè¿™æä¾›äº†ä¸€ç§æ€æƒ³ï¼Œå³å½“æˆ‘ä»¬æƒ³åˆ©ç”¨å‚…ç«‹å¶åŸºå»æ‹Ÿåˆå‡½æ•°çš„æ—¶å€™ï¼Œé™¤äº†æœ¬èº«è®¡ç®—èƒ½åŠ›æœ‰é™å¯¼è‡´çš„å¦¥åï¼Œéœ€è¦æŠŠæ— é™çš„å‡½æ•°æ‹Ÿåˆé—®é¢˜è½¬åŒ–æˆæœ‰é™ç»´çš„æƒ…å†µæ¥åšï¼ŒåŒæ—¶æœ¬èº«è¿™æ ·åšå°±æ˜¯åˆç†çš„ï¼Œå› ä¸ºè¿™é¿å…äº†æ³›åŒ–è¯¯å·®çš„æå‡</p>

<h4 id="whats-function-space">Whatâ€™s function space</h4>

<p>ä¸€èˆ¬çš„å‘é‡ç©ºé—´çš„ä¾‹å­ï¼Œä¸å¦¨å°±ç”¨æ¬§å‡ é‡Œå¾—ç©ºé—´å¥½äº†ï¼Œå¯¹ä¸€ä¸ªä¸‰ç»´çš„æ¬§å¼ç©ºé—´ï¼Œå…¶ä¸­ä»»æ„çš„å‘é‡èƒ½ç”±åŸºè¡¨ç¤ºï¼š
\(\begin{aligned}
&amp;V=x e_{1}+y e_{2}+z e_{3} \\
&amp;x=V \cdot e_{1} \\
&amp;y=V \cdot e_{2} \\
&amp;z=V \cdot e_{3}
\end{aligned}\)
å…¶ä¸­çš„ $\cdot$ è¿ç®—ä¸ºå†…ç§¯  $V \cdot W=V_{x} W_{x}+V_{y} W_{y}+V_{z} W_{z}$</p>

<p>å†…ç§¯å¦‚æ­¤å®šä¹‰ï¼Œæœ‰ä¸€ä¸ªæ›´ç‰©ç†æ„ä¹‰ä¸Šå¥½çš„æ•ˆæœï¼Œå¦‚æœç°åœ¨æœ‰ä¸€ç»„ä¸¤ä¸ªåŸº ${e_{1},e_{2}}$å¼ æˆäº†ä¸€ä¸ªäºŒç»´çš„æ¬§å¼ç©ºé—´ï¼ŒåŒæ—¶æœ‰ä¸€ä¸ªä¸‰ç»´çš„å‘é‡ $v$ ï¼Œåˆ©ç”¨æŠ•å½±å¾—åˆ° ${e_{1},e_{2}}$ å¯¹å…¶çš„æœ€ä½³é€¼è¿‘ $W=\left(V \cdot e_{1}\right) e_{1}+\left(V \cdot e_{2}\right) e_{2}$ã€‚é€šè¿‡å†…ç§¯å¯ä»¥å®šä¹‰å‘é‡ç©ºé—´ä¸Šçš„æŠ•å½±</p>

<p style="text-align: center;"><img src="/images/2021-12-25-Frequency-Fourier-Galerkin/projection_space.png" alt="projection_space" style="zoom:30%;" /></p>

<p>ä¸€èˆ¬çš„å‘é‡ç©ºé—´çš„ç†è§£å¾ˆç›´è§‚ï¼Œé‚£ä¹ˆæŠŠç ”ç©¶çš„å¯¹è±¡æ¢æˆå‡½æ•°ï¼Œåˆ™é—®é¢˜å°±å˜æˆäº†ï¼š</p>

<ul>
  <li>å¦‚ä½•å®šä¹‰å‡½æ•°ç©ºé—´ä¸­çš„åŸº</li>
  <li>å¦‚ä½•å®šä¹‰å‡½æ•°ç©ºé—´ä¸­çš„å†…ç§¯</li>
</ul>

<p>ç¬¬ä¸€ä¸ªé—®é¢˜ç ”ç©¶æœ‰å¾ˆå¤šæ€è·¯äº†ï¼Œæ¯”å¦‚å¤šé¡¹å¼åŸºï¼Œä»¥åŠä¹‹å‰å®šä¹‰çš„å‚…ç«‹å¶åŸºï¼Œé—®é¢˜åœ¨äºå¦‚ä½•å®šä¹‰å‡½æ•°ç©ºé—´ä¸­çš„å†…ç§¯ï¼Œå€ŸåŠ©å‘é‡å€¼å‡½æ•° $\vec{r}(t)=(\ f(t), g(t))\ $ 
\(u \cdot v=\sum u_{i} v_{i}\)
åˆ™å¯¹åº”åˆ°å‡½æ•°çš„æƒ…å†µåˆ™ä¸ºï¼š</p>

<h3 id="fourier-transform-and-application">Fourier Transform and Application</h3>

<h3 id="galerkin-basis-road-to-application-in-neural-network">Galerkin basis, Road to application in Neural Network?</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CVAE</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
  <span class="s">"""Convolutional variational autoencoder."""</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CVAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span>
                <span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span>
                <span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="c1"># No activation
</span>            <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span> <span class="o">+</span> <span class="n">latent_dim</span><span class="p">),</span>
        <span class="p">]</span>

  <span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span>
  <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">eps</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">eps</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">latent_dim</span><span class="p">))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">apply_sigmoid</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>


</code></pre></div></div>

<p>####</p>

<h2 id="reference">Reference</h2>

<p>[1] C.-C. Jay Kuo <a href="https://arxiv.org/abs/1609.04112">Understanding Convolutional Neural Networks with A Mathematical Model</a></p>
:ET